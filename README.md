# ğŸ“„ RAG-Powered PDF QA App

This project is an end-to-end Retrieval-Augmented Generation (RAG) system that lets users:

- Upload a PDF
- Index it using FAISS
- Ask natural language questions about its content
- Get answers using LLMs (via OpenRouter)

Built with **FastAPI**, **LangChain**, **FAISS**, **Streamlit**, and **Docker**.

---

## ğŸš€ Features

| Feature         | Description                                       |
|----------------|---------------------------------------------------|
| ğŸ“„ PDF Upload    | Upload and process PDF documents                 |
| ğŸ” Vector Search | Index and search text chunks using FAISS         |
| ğŸ¤– LLM Answers   | Generate responses using OpenRouter-compatible models |
| ğŸŒ Frontend UI   | Streamlit-based interface for uploads and queries |
| ğŸ³ Dockerized     | Fully containerized backend with Docker Compose |
| ğŸ§ª Tested         | Unit + integration tests using pytest            |

---

## ğŸ§  Tech Stack

- **Backend:** FastAPI, LangChain, FAISS
- **LLM:** OpenRouter (LLaMA 3.3 8B Instruct)
- **Frontend:** Streamlit
- **Containerization:** Docker + Docker Compose
- **Testing:** Pytest + pytest-asyncio

---

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ app/                    # FastAPI backend
â”‚   â”œâ”€â”€ main.py             # API entrypoint
â”‚   â”œâ”€â”€ routes/             # Upload, query, metadata APIs
â”‚   â”œâ”€â”€ services/           # Ingestion, retrieval, generation logic
â”‚   â””â”€â”€ utils/              # PDF parser
â”œâ”€â”€ frontend/               # Streamlit frontend
â”‚   â””â”€â”€ frontend.py
â”œâ”€â”€ tests/                  # Unit and integration tests
â”‚   â””â”€â”€ test_retrieval_query.py
â”œâ”€â”€ Dockerfile              # Backend Docker config
â”œâ”€â”€ docker-compose.yml      # Orchestration
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # This file
```

---

## âš™ï¸ Setup Instructions

### ğŸ”§ Clone the repo
```bash
git clone https://github.com/AnuragSingh457/RAG-Project.git
cd RAG-Project
```

### ğŸ³ Backend: Docker Setup
```bash
docker-compose up --build
```
â¡ï¸ Backend will be live at: `http://localhost:8000`
â¡ï¸ Test it: [http://localhost:8000/docs](http://localhost:8000/docs)

### ğŸŒ Frontend: Streamlit App
```bash
cd frontend
pip install -r requirements.txt  # or: pip install streamlit requests
streamlit run frontend.py
```
â¡ï¸ App will run at: [http://localhost:8501](http://localhost:8501)

---

## ğŸ” Environment Setup

Create a `.env` file (for OpenRouter LLM):

```env
OPENAI_API_KEY=your_openrouter_api_key
OPENAI_API_BASE=https://openrouter.ai/api/v1
```

---

## ğŸ§ª Run Tests

```bash
docker exec -it rag_api env PYTHONPATH=/app pytest tests/
```

Includes:
- PDF upload and FAISS ingestion test
- Querying + LLM answer generation
- API error handling

---

## ğŸŒ Deployment Options

You can deploy this project to:
- ğŸš€ **Streamlit Cloud** (for the frontend)
- ğŸ³ **Render / Railway / Fly.io** (for Dockerized backend)

---

## ğŸ™Œ Credits

- Built with â¤ï¸ using FastAPI, LangChain, Streamlit, and FAISS
- LLMs powered by [OpenRouter](https://openrouter.ai)

---

-You can see the app live at - https://ragproject-mewe49drlug4gkgrqprnjh.streamlit.app/

